"""
Service principal d'orchestration du scraping
"""

import time
import os
from typing import List, Dict, Any, Optional
from app.database.models import Lead
from app.database.database import db
from app.utils.logger import LeadLogger, SystemLogger
from app.utils.validators import is_valid_url, is_social_media_url
from app.scrapers.google_maps_v2_continuous import GoogleMapsScraperV2Continuous
from app.scrapers.scrapy_spider_improved import ScrapyWebsiteScraperImproved
from app.services.screenshot_service import ScreenshotService
from app.services.ai_analysis_service import AIAnalysisService
from app.config import Config
from dotenv import load_dotenv

class ScrapingService:
    """Service principal de scraping"""
    
    def __init__(self):
        # Charger le .env pour garantir la pr√©sence des variables d'environnement
        load_dotenv()
        SystemLogger.info("Initialisation du ScrapingService")
        
        # Initialiser les services de production
        try:
            SystemLogger.info("Tentative d'utilisation des services de production")
            
            # Initialisation des services avec gestion d'erreurs sp√©cifiques
            try:
                self.google_maps_service = GoogleMapsScraperV2Continuous()
                SystemLogger.info("‚úÖ Service Google Maps initialis√©")
            except Exception as e:
                SystemLogger.error(f"‚ùå Erreur initialisation Google Maps: {str(e)}")
                raise ValueError(f"Impossible d'initialiser le service Google Maps: {str(e)}")
            
            try:
                self.website_scraper = ScrapyWebsiteScraperImproved()
                SystemLogger.info("‚úÖ Service de scraping web initialis√©")
            except Exception as e:
                SystemLogger.error(f"‚ùå Erreur initialisation scraper web: {str(e)}")
                raise ValueError(f"Impossible d'initialiser le scraper web: {str(e)}")
            
            try:
                self.screenshot_service = ScreenshotService()
                SystemLogger.info("‚úÖ Service de captures d'√©cran initialis√©")
            except Exception as e:
                SystemLogger.error(f"‚ùå Erreur initialisation service screenshots: {str(e)}")
                raise ValueError(f"Impossible d'initialiser le service de captures d'√©cran: {str(e)}")
            
            try:
                self.ai_analysis_service = AIAnalysisService()
                SystemLogger.info("‚úÖ Service d'analyse IA initialis√©")
            except Exception as e:
                SystemLogger.error(f"‚ùå Erreur initialisation service IA: {str(e)}")
                raise ValueError(f"Impossible d'initialiser le service d'analyse IA: {str(e)}")
            
            # Test rapide de l'API Google Places seulement si une cl√© est configur√©e
            if Config.GOOGLE_PLACES_API_KEY:
                SystemLogger.info("Test de l'API Google Places...")
                try:
                    test_result = self.google_maps_service._geocode_location("Paris, France")
                    if test_result:
                        SystemLogger.info("‚úÖ API Google Places fonctionnelle")
                    else:
                        raise ValueError("API Google Places non fonctionnelle")
                except Exception as e:
                    SystemLogger.error(f"‚ùå Test API Google Places √©chou√©: {str(e)}")
                    raise ValueError(f"Test de l'API Google Places √©chou√©: {str(e)}")
            else:
                SystemLogger.warning("Aucune cl√© API Google Places configur√©e")
                raise ValueError("Pas de cl√© API Google Places")
            
        except ValueError as e:
            SystemLogger.error(f"Erreur de configuration: {str(e)}")
            raise e
        except Exception as e:
            SystemLogger.error(f"Erreur inattendue lors de l'initialisation des services: {str(e)}")
            raise e
    
    def start_scraping_smart(self, location: str, business_type: Optional[str] = "", 
                           max_results: int = 20, min_rating: float = 4.0, 
                           min_reviews: int = 10, radius: int = 5000, anti_hotels: bool = False,
                           wide_search: bool = False) -> Dict[str, Any]:
        """
        D√©marrer le processus de scraping optimis√© avec gestion des zones
        
        Args:
            location: Localisation √† scraper
            business_type: Type d'entreprise
            max_results: Nombre maximum de r√©sultats
            min_rating: Note minimum pour inclure l'entreprise
            min_reviews: Nombre minimum d'avis
            radius: Rayon de recherche en m√®tres
            anti_hotels: Bool√©en pour filtrer les h√¥tels
            
        Returns:
            R√©sultat du scraping avec statistiques
        """
        SystemLogger.info(f"üöÄ [PIPELINE SMART] --- D√âBUT SCRAPING OPTIMIS√â ---")
        SystemLogger.info(f"üìç [PIPELINE SMART] Localisation: {location}")
        SystemLogger.info(f"üè¢ [PIPELINE SMART] Type d'entreprise: {business_type or 'Tous'}")
        SystemLogger.info(f"üìä [PIPELINE SMART] Filtres: note >= {min_rating}, avis >= {min_reviews}")
        SystemLogger.info(f"üìè [PIPELINE SMART] Rayon: {radius}m")
        SystemLogger.info(f"üéØ [PIPELINE SMART] Max r√©sultats: {max_results}")
        
        try:
            # √âtape 1: Cr√©er ou r√©cup√©rer la zone
            SystemLogger.info(f"üó∫Ô∏è [PIPELINE SMART] √âtape 1: Cr√©ation/r√©cup√©ration de la zone...")
            coordinates = self.google_maps_service._geocode_location(location)
            if not coordinates:
                SystemLogger.error(f"‚ùå [PIPELINE SMART] Impossible de g√©ocoder la localisation: {location}")
                return {'success': False, 'message': 'Impossible de g√©ocoder la localisation', 'leads_processed': 0}
            
            lat, lng = coordinates
            SystemLogger.info(f"‚úÖ [PIPELINE SMART] G√©ocodage r√©ussi: {lat:.6f}, {lng:.6f}")
            
            zone_nom = f"{location} - {business_type or 'G√©n√©ral'}"
            
            # Cr√©er la zone si elle n'existe pas
            
            # √âtape 2: Recherche continue jusqu'√† obtenir le nombre de bars uniques souhait√©
            SystemLogger.info(f"üîç [PIPELINE SMART] √âtape 2: Recherche continue Google Maps...")
            SystemLogger.info(f"üîç [PIPELINE SMART] Mode recherche: {'LARGE' if wide_search else 'PR√âCIS'}")
            businesses = self.google_maps_service.search_continuous_until_target(
                location=location,
                target_count=max_results,
                business_type=business_type or "bar",
                radius=radius,
                min_rating=min_rating,
                min_reviews=min_reviews,
                max_pages_per_search=5,
                max_searches=10,
                wide_search=wide_search
            )
            
            # Filtre anti-h√¥tels si demand√©
            if anti_hotels:
                businesses = [b for b in businesses if 'lodging' not in (b.get('types') or [])]
            SystemLogger.info(f"‚úÖ [PIPELINE SMART] Recherche termin√©e: {len(businesses)} entreprises trouv√©es (anti_hotels={anti_hotels})")
            
            if not businesses:
                SystemLogger.warning(f"‚ö†Ô∏è [PIPELINE SMART] Aucune entreprise trouv√©e")
                return {'success': False, 'message': 'Aucune entreprise trouv√©e', 'leads_processed': 0}
            
            # √âtape 3: Traitement de chaque entreprise
            SystemLogger.info(f"üîß [PIPELINE SMART] √âtape 3: Traitement des entreprises...")
            leads_created = 0
            leads_updated = 0
            total_api_cost = 0.005  # Co√ªt du g√©ocodage
            
            for i, business in enumerate(businesses):
                try:
                    name = business.get('name', 'N/A')
                    SystemLogger.info(f"üîß [PIPELINE SMART] --- TRAITEMENT ENTREPRISE {i+1}/{len(businesses)} : {name} ---")
                    
                    # Validation des donn√©es de l'entreprise
                    if not business.get('place_id'):
                        SystemLogger.warning(f"‚ö†Ô∏è [PIPELINE SMART] Entreprise sans place_id: {name}")
                        continue
                    
                    lead = self._process_business_smart(business, None) # Pas de zone_id pour le scraping classique
                    if lead:
                        SystemLogger.info(f"‚úÖ [PIPELINE SMART] Lead trait√©: {lead.nom} (ID: {lead.id})")
                        if lead.id:  # Lead existant mis √† jour
                            leads_updated += 1
                            SystemLogger.info(f"üîÑ [PIPELINE SMART] Lead mis √† jour: {lead.nom}")
                        else:  # Nouveau lead
                            leads_created += 1
                            SystemLogger.info(f"üÜï [PIPELINE SMART] Nouveau lead cr√©√©: {lead.nom}")
                    else:
                        SystemLogger.warning(f"‚ö†Ô∏è [PIPELINE SMART] √âchec du traitement: {name}")
                    
                    # D√©lai entre les requ√™tes
                    if i < len(businesses) - 1:
                        time.sleep(Config.DELAY_BETWEEN_REQUESTS)
                        
                except ValueError as e:
                    SystemLogger.error(f"‚ùå [PIPELINE SMART] Erreur de validation pour {business.get('name', 'N/A')}: {str(e)}")
                    continue
                except ConnectionError as e:
                    SystemLogger.error(f"‚ùå [PIPELINE SMART] Erreur de connexion pour {business.get('name', 'N/A')}: {str(e)}")
                    continue
                except Exception as e:
                    SystemLogger.error(f"‚ùå [PIPELINE SMART] Erreur inattendue pour {business.get('name', 'N/A')}: {str(e)}")
                    continue
            
            # Calculer le co√ªt total (g√©ocodage + Place Details)
            total_api_cost += len(businesses) * 0.0179
            
            SystemLogger.info(f"‚úÖ [PIPELINE SMART] --- FIN TRAITEMENT ENTREPRISES ---")
            SystemLogger.info(f"üìä [PIPELINE SMART] R√©sultats finaux:")
            SystemLogger.info(f"   - Leads trait√©s: {len(businesses)}")
            SystemLogger.info(f"   - Leads cr√©√©s: {leads_created}")
            SystemLogger.info(f"   - Leads mis √† jour: {leads_updated}")
            SystemLogger.info(f"üí∞ [PIPELINE SMART] Co√ªt API total: ${total_api_cost:.4f}")
            
            # Sauvegarder les changements
            db.session.commit()
            SystemLogger.info(f"üíæ [PIPELINE SMART] Commit DB effectu√©")
            result = {
                'success': True,
                'message': f'Scraping optimis√© termin√© avec succ√®s',
                'leads_processed': len(businesses),
                'leads_created': leads_created,
                'leads_updated': leads_updated,
                'api_cost': total_api_cost,
                'optimization_savings': f"{(len(businesses) * 0.0179) - total_api_cost:.4f}"
            }
            
            SystemLogger.info(f"üéâ [PIPELINE SMART] --- FIN SCRAPING OPTIMIS√â ---")
            return result
            
        except Exception as e:
            SystemLogger.error(f"‚ùå [PIPELINE SMART] Erreur globale scraping: {str(e)}")
            db.session.rollback()
            return {'success': False, 'message': f'Erreur: {str(e)}', 'leads_processed': 0}
    
    def start_scraping(self, location: str, business_type: Optional[str] = "", max_results: int = 20) -> Dict[str, Any]:
        """
        D√©marrer le processus de scraping classique
        
        Args:
            location: Localisation √† scraper
            business_type: Type d'entreprise
            max_results: Nombre maximum de r√©sultats
            
        Returns:
            R√©sultat du scraping
        """
        SystemLogger.info(f"üöÄ [PIPELINE CLASSIC] --- D√âBUT SCRAPING CLASSIQUE ---")
        SystemLogger.info(f"üìç [PIPELINE CLASSIC] Localisation: {location}")
        SystemLogger.info(f"üè¢ [PIPELINE CLASSIC] Type d'entreprise: {business_type or 'Tous'}")
        SystemLogger.info(f"üéØ [PIPELINE CLASSIC] Max r√©sultats: {max_results}")
        
        try:
            # Recherche Google Maps
            SystemLogger.info(f"üîç [PIPELINE CLASSIC] Recherche Google Maps...")
            businesses = self.google_maps_service.search_nearby(
                location=location,
                radius=5000,
                business_type=business_type,
                max_results=max_results
            )
            
            SystemLogger.info(f"‚úÖ [PIPELINE CLASSIC] Recherche termin√©e: {len(businesses)} entreprises trouv√©es")
            
            if not businesses:
                SystemLogger.warning(f"‚ö†Ô∏è [PIPELINE CLASSIC] Aucune entreprise trouv√©e")
                return {'success': False, 'message': 'Aucune entreprise trouv√©e', 'leads_processed': 0}
            
            # Traitement de chaque entreprise
            SystemLogger.info(f"üîß [PIPELINE CLASSIC] Traitement des entreprises...")
            leads_created = 0
            leads_updated = 0
            
            for i, business in enumerate(businesses):
                try:
                    name = business.get('name', 'N/A')
                    SystemLogger.info(f"üîß [PIPELINE CLASSIC] --- TRAITEMENT ENTREPRISE {i+1}/{len(businesses)} : {name} ---")
                    
                    # Utiliser la m√©thode smart pour le traitement
                    lead = self._process_business_smart(business, None)  # Pas de zone_id pour le scraping classique
                    if lead:
                        SystemLogger.info(f"‚úÖ [PIPELINE CLASSIC] Lead trait√©: {lead.nom} (ID: {lead.id})")
                        if lead.id:  # Lead existant mis √† jour
                            leads_updated += 1
                            SystemLogger.info(f"üîÑ [PIPELINE CLASSIC] Lead mis √† jour: {lead.nom}")
                        else:  # Nouveau lead
                            leads_created += 1
                            SystemLogger.info(f"üÜï [PIPELINE CLASSIC] Nouveau lead cr√©√©: {lead.nom}")
                    else:
                        SystemLogger.warning(f"‚ö†Ô∏è [PIPELINE CLASSIC] √âchec du traitement: {name}")
                    
                    # D√©lai entre les requ√™tes
                    if i < len(businesses) - 1:
                        time.sleep(Config.DELAY_BETWEEN_REQUESTS)
                        
                except Exception as e:
                    SystemLogger.error(f"‚ùå [PIPELINE CLASSIC] Erreur lors du traitement de l'entreprise {business.get('name', 'N/A')}: {str(e)}")
                    continue
            
            # Sauvegarder les changements
            db.session.commit()
            SystemLogger.info(f"üíæ [PIPELINE CLASSIC] Commit DB effectu√©")
            
            result = {
                'success': True,
                'message': f'Scraping classique termin√© avec succ√®s',
                'leads_processed': len(businesses),
                'leads_created': leads_created,
                'leads_updated': leads_updated
            }
            
            SystemLogger.info(f"üéâ [PIPELINE CLASSIC] --- FIN SCRAPING CLASSIQUE ---")
            return result
            
        except Exception as e:
            SystemLogger.error(f"‚ùå [PIPELINE CLASSIC] Erreur globale scraping: {str(e)}")
            db.session.rollback()
            return {'success': False, 'message': f'Erreur: {str(e)}', 'leads_processed': 0}
    
    def _process_business_smart(self, business_data: Dict[str, Any], zone_id: Optional[int] = None) -> Optional[Lead]:
        """Traiter une entreprise avec les nouvelles fonctionnalit√©s optimis√©es"""
        SystemLogger.info(f"üîß [PROCESS SMART] D√©but du traitement: {business_data.get('name')}")
        
        # V√©rifier si le lead existe d√©j√†
        lead = Lead.query.filter_by(nom=business_data.get('name')).first()
        
        if not lead:
            # Cr√©er un nouveau lead
            SystemLogger.info(f"üÜï [PROCESS SMART] Cr√©ation d'un nouveau lead")
            lead = Lead()
            lead.nom = business_data.get('name')
            
            # Stocker les donn√©es Google Maps dans les champs d√©di√©s
            lead.google_maps_adresse = business_data.get('address') or business_data.get('formatted_address')
            lead.google_maps_telephone = business_data.get('phone') or business_data.get('formatted_phone_number')
            
            # Garder les champs existants pour compatibilit√©
            lead.adresse = business_data.get('address') or business_data.get('formatted_address')
            lead.telephone = business_data.get('phone') or business_data.get('formatted_phone_number')
            
            lead.note_google = business_data.get('rating')
            lead.nb_avis_google = business_data.get('user_ratings_total')
            lead.business_type = business_data.get('business_type')  # Type r√©el de Google Places
            
            # Stocker les coordonn√©es GPS
            latitude = business_data.get('latitude')
            longitude = business_data.get('longitude')
            if latitude and longitude:
                lead.latitude = latitude
                lead.longitude = longitude
                SystemLogger.info(f"üìç [PROCESS SMART] Coordonn√©es GPS stock√©es: {latitude:.6f}, {longitude:.6f}")
            else:
                SystemLogger.warning(f"‚ö†Ô∏è [PROCESS SMART] Coordonn√©es GPS manquantes")
            
            lead.statut_scraping = 'en_cours'
            
            db.session.add(lead)
            db.session.flush()  # Pour obtenir l'ID
            SystemLogger.info(f"‚úÖ [PROCESS SMART] Nouveau lead cr√©√© avec ID: {lead.id}")
        else:
            SystemLogger.info(f"üîÑ [PROCESS SMART] Lead existant trouv√©: {lead.nom} (ID: {lead.id})")
            # Mettre √† jour le business_type si pas encore d√©fini
            if not lead.business_type and business_data.get('business_type'):
                lead.business_type = business_data.get('business_type')
                SystemLogger.info(f"üîÑ [PROCESS SMART] Business type mis √† jour: {lead.business_type}")
        
        # Logger pour ce lead
        lead_logger = LeadLogger(lead.id, lead.nom)
        lead_logger.info("üöÄ [PROCESS SMART] D√©but du traitement optimis√©")
        
        try:
            # √âtape 1: Validation des donn√©es Google Maps
            if not business_data.get('name'):
                raise ValueError("Nom de l'entreprise manquant")
            
            lead_logger.info("‚úÖ [PROCESS SMART] √âtape 1: Donn√©es Google Maps OK")
            # √âtape 1: Donn√©es Google Maps
            lead.update_log("google_maps_scraped: OK")
            
            # √âtape 2: Site web
            website_url = business_data.get('website')
            if website_url and is_valid_url(website_url):
                lead_logger.info(f"üåê [PROCESS SMART] √âtape 2: Site web trouv√©: {website_url}")
                lead.site_web = website_url
                lead_logger.info(f"‚úÖ [PROCESS SMART] Site web enregistr√©: {website_url}")
                
                # V√©rifier si c'est un r√©seau social
                is_social, platform = is_social_media_url(website_url)
                if is_social:
                    lead_logger.info(f"üì± [PROCESS SMART] URL d√©tect√©e comme r√©seau social: {platform}")
                    if platform == 'facebook':
                        lead_logger.info(f"üìò [PROCESS SMART] Facebook d√©tect√©: {website_url}")
                        lead.facebook_url = website_url
                    elif platform == 'instagram':
                        lead_logger.info(f"üì∑ [PROCESS SMART] Instagram d√©tect√©: {website_url}")
                        lead.instagram_url = website_url
                    
                    # Scraper le r√©seau social
                    self._scrape_social_media(lead, lead_logger)
                else:
                    lead_logger.info(f"üåê [PROCESS SMART] Scraping du site web classique...")
                    # Scraper le site web
                    self._scrape_website(lead, lead_logger)
                    
                    # APR√àS l'analyse IA du site web, v√©rifier si des r√©seaux sociaux ont √©t√© trouv√©s
                    if lead.ai_analysis:
                        reseaux_sociaux = lead.ai_analysis.get('reseaux_sociaux', {})
                        facebook_found = False
                        instagram_found = False
                        
                        if reseaux_sociaux.get('facebook'):
                            lead_logger.info(f"üìò [PROCESS SMART] Facebook trouv√© via IA: {reseaux_sociaux['facebook']}")
                            lead.facebook_url = reseaux_sociaux['facebook']
                            facebook_found = True
                        
                        if reseaux_sociaux.get('instagram'):
                            lead_logger.info(f"üì∑ [PROCESS SMART] Instagram trouv√© via IA: {reseaux_sociaux['instagram']}")
                            lead.instagram_url = reseaux_sociaux['instagram']
                            instagram_found = True
                        
                        # Lancer l'analyse IA des r√©seaux sociaux si au moins un a √©t√© trouv√©
                        if facebook_found or instagram_found:
                            lead_logger.info("[PROCESS SMART] Lancement de l'analyse IA des r√©seaux sociaux...")
                            self._scrape_social_media(lead, lead_logger)
            else:
                lead_logger.info("‚ö†Ô∏è [PROCESS SMART] Aucun site web valide trouv√©")
                lead.update_log("site_web: NOK (pas d'URL)")
            
            # √âtape 3: R√©seaux sociaux (si pas d√©j√† fait)
            if not lead.facebook_url and business_data.get('facebook_url'):
                lead_logger.info(f"üìò [PROCESS SMART] Facebook additionnel d√©tect√©: {business_data.get('facebook_url')}")
                lead.facebook_url = business_data.get('facebook_url')
                self._scrape_social_media(lead, lead_logger)
            
            if not lead.instagram_url and business_data.get('instagram_url'):
                lead_logger.info(f"üì∑ [PROCESS SMART] Instagram additionnel d√©tect√©: {business_data.get('instagram_url')}")
                lead.instagram_url = business_data.get('instagram_url')
                self._scrape_social_media(lead, lead_logger)
            
            # Finaliser le statut
            lead.set_statut('succ√®s')
            lead.update_log("status: succ√®s")
            lead_logger.info("‚úÖ [PROCESS SMART] Statut scraping finalis√© √† 'succ√®s'")

            # Appel du scoring IA (RAG) pour g√©n√©rer l'argumentaire
            try:
                from app.services.ai_analysis_service import AIAnalysisService
                ai_service = AIAnalysisService()
                ai_result = ai_service.score_lead_with_rag(lead)
                
                # Stocker les r√©sultats du scoring IA
                if ai_result.get('score'):
                    lead.score_ia = ai_result['score']
                if ai_result.get('argumentaire'):
                    lead.argumentaire_ia = ai_result['argumentaire']
                
                lead_logger.info(f"‚úÖ [PROCESS SMART] Scoring IA effectu√©: {ai_result}")
            except Exception as e:
                lead_logger.error(f"‚ùå [PROCESS SMART] Erreur scoring IA: {str(e)}")

            SystemLogger.info(f"‚úÖ [PROCESS SMART] Traitement termin√© avec succ√®s: {lead.nom}")
            return lead
            
        except Exception as e:
            lead_logger.error(f"‚ùå [PROCESS SMART] Erreur lors du traitement: {str(e)}")
            lead.set_statut('erreur')
            lead.update_log(f"error: {str(e)}")
            SystemLogger.error(f"‚ùå [PROCESS SMART] Erreur lors du traitement de {lead.nom}: {str(e)}")
            return None
    
    def _scrape_website(self, lead: Lead, logger: LeadLogger):
        """
        Scrape le site web avec le nouveau syst√®me IA
        """
        if not lead.site_web:
            logger.info("‚ùå Pas d'URL de site web √† scraper")
            return
        
        try:
            logger.info(f"üåê [WEBSITE] D√©but scraping IA pour {lead.site_web}")
            
            # Validation de l'URL
            if not is_valid_url(lead.site_web):
                logger.error(f"‚ùå [WEBSITE] URL invalide: {lead.site_web}")
                return
            
            # Utiliser le nouveau scraper IA
            scraper = ScrapyWebsiteScraperImproved()
            result = scraper.scrape_website_with_ai(lead.site_web)
            
            if result and result.get('scraping_success'):
                ai_analysis = result.get('ai_analysis', {})
                
                # Mettre √† jour le lead avec les donn√©es IA
                self._update_lead_with_ai_analysis(lead, ai_analysis, logger)
                
                logger.info(f"‚úÖ [WEBSITE] Scraping IA termin√© pour {lead.site_web}")
            else:
                error_msg = result.get('error', 'Erreur inconnue') if result else 'Pas de r√©sultat'
                logger.error(f"‚ùå [WEBSITE] √âchec du scraping IA pour {lead.site_web}: {error_msg}")
                
        except ConnectionError as e:
            logger.error(f"‚ùå [WEBSITE] Erreur de connexion pour {lead.site_web}: {str(e)}")
        except TimeoutError as e:
            logger.error(f"‚ùå [WEBSITE] Timeout pour {lead.site_web}: {str(e)}")
        except ValueError as e:
            logger.error(f"‚ùå [WEBSITE] Erreur de validation pour {lead.site_web}: {str(e)}")
        except Exception as e:
            logger.error(f"‚ùå [WEBSITE] Erreur inattendue pour {lead.site_web}: {str(e)}")
    
    def _update_lead_with_ai_analysis(self, lead: Lead, ai_analysis: Dict[str, Any], logger: LeadLogger):
        """
        Met √† jour le lead avec les donn√©es de l'analyse IA (site web)
        """
        try:
            # Contact (Site Web)
            contact = ai_analysis.get('contact', {})
            if contact.get('emails'):
                lead.site_web_email = contact['emails'][0]
            if contact.get('telephones'):
                lead.site_web_telephone = contact['telephones'][0]
            if contact.get('adresse'):
                lead.site_web_adresse = contact['adresse']
            
            # Entreprise (Site Web)
            entreprise = ai_analysis.get('entreprise', {})
            if entreprise.get('description'):
                lead.site_web_description = entreprise['description']
            
            # Informations pratiques (Site Web)
            pratique = ai_analysis.get('pratique', {})
            if pratique.get('horaires'):
                lead.site_web_horaires = pratique['horaires']
            if pratique.get('services'):
                lead.site_web_services = ', '.join(pratique['services']) if isinstance(pratique['services'], list) else pratique['services']
            
            # R√©seaux sociaux (Site Web) - avec validation des URLs
            reseaux = ai_analysis.get('reseaux_sociaux', {})
            if reseaux.get('facebook'):
                facebook_url = reseaux['facebook']
                # Validation de l'URL Facebook
                if is_valid_url(facebook_url) and 'facebook.com' in facebook_url and not any(ext in facebook_url.lower() for ext in ['.css', '.js', '.png', '.jpg', '.gif', '.ico', '.svg', '.woff', '.ttf']):
                    lead.facebook_url = facebook_url
                    logger.info(f"üìò [LEAD] Facebook trouv√© via IA: {facebook_url}")
                else:
                    logger.warning(f"‚ö†Ô∏è [LEAD] URL Facebook invalide ignor√©e: {facebook_url}")
            
            if reseaux.get('instagram'):
                instagram_url = reseaux['instagram']
                # Validation de l'URL Instagram
                if is_valid_url(instagram_url) and 'instagram.com' in instagram_url and not any(ext in instagram_url.lower() for ext in ['.css', '.js', '.png', '.jpg', '.gif', '.ico', '.svg', '.woff', '.ttf']):
                    lead.instagram_url = instagram_url
                    logger.info(f"üì∑ [LEAD] Instagram trouv√© via IA: {instagram_url}")
                else:
                    logger.warning(f"‚ö†Ô∏è [LEAD] URL Instagram invalide ignor√©e: {instagram_url}")
            
            # Sauvegarder l'analyse IA compl√®te
            lead.ai_analysis = ai_analysis
            
            # Sauvegarder en base
            db.session.commit()
            
            logger.info(f"‚úÖ [LEAD] Donn√©es site web mises √† jour")
            
        except Exception as e:
            logger.error(f"‚ùå [LEAD] Erreur mise √† jour lead: {str(e)}")
    
    def _scrape_social_media(self, lead: Lead, logger: LeadLogger):
        """Nouvelle m√©thode : Capture d'√©cran + analyse IA des r√©seaux sociaux"""
        logger.info("[PIPELINE] --- D√âBUT SCRAPING SOCIAL MEDIA ---")
        try:
            logger.info("[PIPELINE] Capture d'√©cran des r√©seaux sociaux...")
            # Pr√©parer les donn√©es du lead pour la capture
            lead_data = {
                'id': lead.id,
                'facebook_url': lead.facebook_url,
                'instagram_url': lead.instagram_url
            }
            
            # √âtape 1: Capture d'√©cran
            screenshots = self.screenshot_service.capture_social_media(lead_data)
            
            # Sauvegarder les chemins des captures d'√©cran
            if screenshots.get('facebook_screenshot'):
                lead.facebook_screenshot_path = screenshots['facebook_screenshot']
                logger.info(f"Capture Facebook sauvegard√©e: {lead.facebook_screenshot_path}")
            
            if screenshots.get('instagram_screenshot'):
                lead.instagram_screenshot_path = screenshots['instagram_screenshot']
                logger.info(f"Capture Instagram sauvegard√©e: {lead.instagram_screenshot_path}")
            
            # √âtape 2: Analyse IA des captures d'√©cran
            logger.info("[PIPELINE] Analyse IA des captures d'√©cran...")
            ai_service = AIAnalysisService()
            
            # Analyser chaque screenshot s√©par√©ment
            ai_results = {}
            if screenshots.get('facebook_screenshot'):
                fb_result = ai_service.analyze_social_media_screenshots(screenshots['facebook_screenshot'], 'facebook')
                ai_results['facebook_data'] = fb_result
                
                # Stocker les donn√©es Facebook dans les champs appropri√©s
                if fb_result.get('followers'):
                    followers_str = fb_result['followers']
                    try:
                        # Nettoyer la cha√Æne et g√©rer les minuscules
                        followers_clean = followers_str.strip().upper()
                        if 'K' in followers_clean:
                            followers_num = float(followers_clean.replace('K', '').replace(',', '.').replace(' ', '')) * 1000
                            lead.nb_followers_facebook = int(followers_num)
                        elif 'M' in followers_clean:
                            followers_num = float(followers_clean.replace('M', '').replace(',', '.').replace(' ', '')) * 1000000
                            lead.nb_followers_facebook = int(followers_num)
                        else:
                            # Essayer de convertir directement
                            followers_clean = followers_str.replace(',', '').replace(' ', '')
                            lead.nb_followers_facebook = int(followers_clean)
                    except Exception as e:
                        logger.warning(f"Erreur conversion followers Facebook: {str(e)}")
                        # Essayer une conversion plus robuste
                        try:
                            import re
                            # Extraire les chiffres avec regex
                            numbers = re.findall(r'\d+(?:\.\d+)?', followers_str)
                            if numbers:
                                if 'k' in followers_str.lower():
                                    lead.nb_followers_facebook = int(float(numbers[0]) * 1000)
                                elif 'm' in followers_str.lower():
                                    lead.nb_followers_facebook = int(float(numbers[0]) * 1000000)
                                else:
                                    lead.nb_followers_facebook = int(float(numbers[0]))
                                logger.info(f"‚úÖ Conversion followers Facebook r√©ussie avec regex: {lead.nb_followers_facebook}")
                        except Exception as e2:
                            logger.warning(f"√âchec conversion followers Facebook avec regex: {str(e2)}")
                
                if fb_result.get('likes') and fb_result['likes'] != 'Non visible':
                    likes_str = fb_result['likes']
                    try:
                        # Nettoyer la cha√Æne et g√©rer les minuscules
                        likes_clean = likes_str.strip().upper()
                        if 'K' in likes_clean:
                            likes_num = float(likes_clean.replace('K', '').replace(',', '.').replace(' ', '')) * 1000
                            lead.nb_likes_facebook = int(likes_num)
                        elif 'M' in likes_clean:
                            likes_num = float(likes_clean.replace('M', '').replace(',', '.').replace(' ', '')) * 1000000
                            lead.nb_likes_facebook = int(likes_num)
                        else:
                            # Essayer de convertir directement
                            likes_clean = likes_str.replace(',', '').replace(' ', '')
                            lead.nb_likes_facebook = int(likes_clean)
                    except Exception as e:
                        logger.warning(f"Erreur conversion likes Facebook: {str(e)}")
                        # Essayer une conversion plus robuste
                        try:
                            import re
                            # Extraire les chiffres avec regex
                            numbers = re.findall(r'\d+(?:\.\d+)?', likes_str)
                            if numbers:
                                if 'k' in likes_str.lower():
                                    lead.nb_likes_facebook = int(float(numbers[0]) * 1000)
                                elif 'm' in likes_str.lower():
                                    lead.nb_likes_facebook = int(float(numbers[0]) * 1000000)
                                else:
                                    lead.nb_likes_facebook = int(float(numbers[0]))
                                logger.info(f"‚úÖ Conversion likes Facebook r√©ussie avec regex: {lead.nb_likes_facebook}")
                        except Exception as e2:
                            logger.warning(f"√âchec conversion likes Facebook avec regex: {str(e2)}")
                
                # Stocker l'intro Facebook (informations compl√®tes)
                if fb_result.get('intro'):
                    lead.intro_facebook = fb_result['intro']
                elif fb_result.get('description'):
                    lead.description_facebook = fb_result['description']
                
                # Stocker les informations de contact Facebook
                if fb_result.get('contact_info') and isinstance(fb_result['contact_info'], dict):
                    contact = fb_result['contact_info']
                    if contact.get('phone') and contact['phone'] != 'Non visible':
                        lead.facebook_telephone = contact['phone']
                    if contact.get('email') and contact['email'] != 'Non visible':
                        lead.facebook_email = contact['email']
                    if contact.get('address') and contact['address'] != 'Non visible':
                        lead.facebook_adresse = contact['address']
                    if contact.get('website') and contact['website'] != 'Non visible':
                        lead.facebook_site_web = contact['website']
                
                # Cr√©er une cha√Æne de statistiques pour l'affichage
                stats_parts = []
                if fb_result.get('followers'):
                    stats_parts.append(f"{fb_result['followers']} followers")
                if fb_result.get('likes') and fb_result['likes'] != 'Non visible':
                    stats_parts.append(f"{fb_result['likes']} likes")
                if stats_parts:
                    lead.facebook_stats = " ‚Ä¢ ".join(stats_parts)
            
            if screenshots.get('instagram_screenshot'):
                insta_result = ai_service.analyze_social_media_screenshots(screenshots['instagram_screenshot'], 'instagram')
                ai_results['instagram_data'] = insta_result
                
                # Stocker les donn√©es Instagram dans les champs appropri√©s
                if insta_result.get('followers'):
                    followers_str = insta_result['followers']
                    try:
                        # Nettoyer la cha√Æne et g√©rer les minuscules
                        followers_clean = followers_str.strip().upper()
                        if 'K' in followers_clean:
                            followers_num = float(followers_clean.replace('K', '').replace(',', '.').replace(' ', '')) * 1000
                            lead.nb_followers_instagram = int(followers_num)
                        elif 'M' in followers_clean:
                            followers_num = float(followers_clean.replace('M', '').replace(',', '.').replace(' ', '')) * 1000000
                            lead.nb_followers_instagram = int(followers_num)
                        else:
                            # Essayer de convertir directement
                            followers_clean = followers_str.replace(',', '').replace(' ', '')
                            lead.nb_followers_instagram = int(followers_clean)
                    except Exception as e:
                        logger.warning(f"Erreur conversion followers Instagram: {str(e)}")
                        # Essayer une conversion plus robuste
                        try:
                            import re
                            # Extraire les chiffres avec regex
                            numbers = re.findall(r'\d+(?:\.\d+)?', followers_str)
                            if numbers:
                                if 'k' in followers_str.lower():
                                    lead.nb_followers_instagram = int(float(numbers[0]) * 1000)
                                elif 'm' in followers_str.lower():
                                    lead.nb_followers_instagram = int(float(numbers[0]) * 1000000)
                                else:
                                    lead.nb_followers_instagram = int(float(numbers[0]))
                                logger.info(f"‚úÖ Conversion followers Instagram r√©ussie avec regex: {lead.nb_followers_instagram}")
                        except Exception as e2:
                            logger.warning(f"√âchec conversion followers Instagram avec regex: {str(e2)}")
                
                # Traiter le following Instagram
                if insta_result.get('following'):
                    following_str = insta_result['following']
                    try:
                        # Nettoyer la cha√Æne et g√©rer les minuscules
                        following_clean = following_str.strip().upper()
                        if 'K' in following_clean:
                            following_num = float(following_clean.replace('K', '').replace(',', '.').replace(' ', '')) * 1000
                            lead.nb_following_instagram = int(following_num)
                        elif 'M' in following_clean:
                            following_num = float(following_clean.replace('M', '').replace(',', '.').replace(' ', '')) * 1000000
                            lead.nb_following_instagram = int(following_num)
                        else:
                            # Essayer de convertir directement
                            following_clean = following_str.replace(',', '').replace(' ', '')
                            lead.nb_following_instagram = int(following_clean)
                    except Exception as e:
                        logger.warning(f"Erreur conversion following Instagram: {str(e)}")
                        # Essayer une conversion plus robuste
                        try:
                            import re
                            # Extraire les chiffres avec regex
                            numbers = re.findall(r'\d+(?:\.\d+)?', following_str)
                            if numbers:
                                if 'k' in following_str.lower():
                                    lead.nb_following_instagram = int(float(numbers[0]) * 1000)
                                elif 'm' in following_str.lower():
                                    lead.nb_following_instagram = int(float(numbers[0]) * 1000000)
                                else:
                                    lead.nb_following_instagram = int(float(numbers[0]))
                                logger.info(f"‚úÖ Conversion following Instagram r√©ussie avec regex: {lead.nb_following_instagram}")
                        except Exception as e2:
                            logger.warning(f"√âchec conversion following Instagram avec regex: {str(e2)}")
                
                if insta_result.get('posts'):
                    posts_str = insta_result['posts']
                    try:
                        # Nettoyer la cha√Æne et g√©rer les minuscules
                        posts_clean = posts_str.strip().upper()
                        if 'K' in posts_clean:
                            posts_num = float(posts_clean.replace('K', '').replace(',', '.').replace(' ', '')) * 1000
                            lead.nb_posts_instagram = int(posts_num)
                        elif 'M' in posts_clean:
                            posts_num = float(posts_clean.replace('M', '').replace(',', '.').replace(' ', '')) * 1000000
                            lead.nb_posts_instagram = int(posts_num)
                        else:
                            # Essayer de convertir directement
                            posts_clean = posts_str.replace(',', '').replace(' ', '')
                            lead.nb_posts_instagram = int(posts_clean)
                    except Exception as e:
                        logger.warning(f"Erreur conversion posts Instagram: {str(e)}")
                        # Essayer une conversion plus robuste
                        try:
                            import re
                            # Extraire les chiffres avec regex
                            numbers = re.findall(r'\d+(?:\.\d+)?', posts_str)
                            if numbers:
                                if 'k' in posts_str.lower():
                                    lead.nb_posts_instagram = int(float(numbers[0]) * 1000)
                                elif 'm' in posts_str.lower():
                                    lead.nb_posts_instagram = int(float(numbers[0]) * 1000000)
                                else:
                                    lead.nb_posts_instagram = int(float(numbers[0]))
                                logger.info(f"‚úÖ Conversion posts Instagram r√©ussie avec regex: {lead.nb_posts_instagram}")
                        except Exception as e2:
                            logger.warning(f"√âchec conversion posts Instagram avec regex: {str(e2)}")
                
                # Stocker la bio Instagram
                if insta_result.get('bio'):
                    lead.bio_instagram = insta_result['bio']
                elif insta_result.get('description'):
                    lead.bio_instagram = insta_result['description']
                
                # Stocker les informations de contact Instagram
                if insta_result.get('contact_info') and isinstance(insta_result['contact_info'], dict):
                    contact = insta_result['contact_info']
                    if contact.get('phone') and contact['phone'] != 'Non visible':
                        lead.instagram_telephone = contact['phone']
                    if contact.get('email') and contact['email'] != 'Non visible':
                        lead.instagram_email = contact['email']
                    if contact.get('address') and contact['address'] != 'Non visible':
                        lead.instagram_adresse = contact['address']
                    if contact.get('website') and contact['website'] != 'Non visible':
                        lead.instagram_site_web = contact['website']
                
                # Cr√©er une cha√Æne de statistiques pour l'affichage
                stats_parts = []
                if insta_result.get('followers'):
                    stats_parts.append(f"{insta_result['followers']} followers")
                if insta_result.get('posts'):
                    stats_parts.append(f"{insta_result['posts']} posts")
                if stats_parts:
                    lead.instagram_stats = " ‚Ä¢ ".join(stats_parts)
            
            # Traiter les r√©sultats Facebook et Instagram (donn√©es d√©j√† trait√©es dans les sections pr√©c√©dentes)
            if ai_results.get('facebook_data'):
                fb_data = ai_results['facebook_data']
                logger.info(f"üìä [FACEBOOK] Donn√©es extraites: {fb_data}")
                lead.update_ai_log(f"Analyse Facebook IA r√©ussie: {lead.nb_followers_facebook} followers")
            
            if ai_results.get('instagram_data'):
                insta_data = ai_results['instagram_data']
                logger.info(f"üìä [INSTAGRAM] Donn√©es extraites: {insta_data}")
                lead.update_ai_log(f"Analyse Instagram IA r√©ussie: {lead.nb_followers_instagram} followers")
            
            # √âtape 3: SCORING D'OPPORTUNIT√â (NOUVELLE √âTAPE)
            logger.info("[PIPELINE] Calcul du score d'opportunit√©...")
            try:
                # Calculer le score d'opportunit√© bas√© sur les donn√©es collect√©es
                score = self._calculate_opportunity_score(lead)
                lead.score_opportunite = score
                lead.update_ai_log(f"Score d'opportunit√© calcul√©: {score}/100")
                logger.info(f"Score d'opportunit√©: {score}/100")
            except Exception as e:
                logger.error(f"Erreur calcul score d'opportunit√©: {str(e)}")
                lead.update_ai_log(f"Erreur calcul score: {str(e)}")
            
            # Finaliser le statut
            if ai_results.get('analysis_success'):
                lead.set_ai_status('succ√®s')
                lead.update_ai_log("Analyse IA termin√©e avec succ√®s")
            else:
                lead.set_ai_status('erreur')
                lead.update_ai_log("Erreur lors de l'analyse IA")
            
            logger.info("[PIPELINE] Commit DB apr√®s social media.")
            db.session.commit()
            logger.info("Analyse IA des r√©seaux sociaux termin√©e avec succ√®s")
            
        except Exception as e:
            logger.error(f"Erreur lors de l'analyse IA des r√©seaux sociaux: {str(e)}")
            lead.set_ai_status('erreur')
            lead.update_ai_log(f"Erreur: {str(e)}")
            db.session.commit()
    
    def _calculate_opportunity_score(self, lead: Lead) -> float:
        """
        Calculer un score d'opportunit√© (0-100) bas√© sur les donn√©es du lead
        
        Args:
            lead: Le lead √† analyser
            
        Returns:
            Score d'opportunit√© entre 0 et 100
        """
        score = 0.0
        
        # 1. Score Google Maps (25 points max)
        if lead.note_google:
            # Note Google (0-5) ‚Üí 0-15 points
            score += (lead.note_google / 5.0) * 15
        if lead.nb_avis_google:
            # Nombre d'avis ‚Üí 0-10 points (plus d'avis = plus d'engagement)
            if lead.nb_avis_google >= 100:
                score += 10
            elif lead.nb_avis_google >= 50:
                score += 7
            elif lead.nb_avis_google >= 20:
                score += 5
            elif lead.nb_avis_google >= 10:
                score += 3
            else:
                score += 1
        
        # 2. Score Site Web (20 points max)
        if lead.site_web:
            score += 5  # Pr√©sence d'un site web
            if lead.has_video_on_site:
                score += 5  # Pr√©sence de vid√©os
            if lead.has_images_on_site:
                score += 3  # Pr√©sence d'images
            if lead.contact_form_detecte:
                score += 3  # Formulaire de contact
            if lead.produits_services_detectes:
                score += 2  # Produits/services d√©tect√©s
            if lead.email:
                score += 2  # Email de contact
        
        # 3. Score Facebook (25 points max)
        if lead.facebook_url:
            score += 5  # Pr√©sence Facebook
            if lead.nb_followers_facebook:
                # Followers Facebook ‚Üí 0-15 points
                if lead.nb_followers_facebook >= 10000:
                    score += 15
                elif lead.nb_followers_facebook >= 5000:
                    score += 12
                elif lead.nb_followers_facebook >= 1000:
                    score += 10
                elif lead.nb_followers_facebook >= 500:
                    score += 7
                elif lead.nb_followers_facebook >= 100:
                    score += 5
                else:
                    score += 2
            if lead.description_facebook:
                score += 3  # Description pr√©sente
            if lead.intro_facebook:
                score += 2  # Intro compl√®te
        
        # 4. Score Instagram (20 points max)
        if lead.instagram_url or lead.instagram_handle:
            score += 5  # Pr√©sence Instagram
            if lead.nb_followers_instagram:
                # Followers Instagram ‚Üí 0-10 points
                if lead.nb_followers_instagram >= 10000:
                    score += 10
                elif lead.nb_followers_instagram >= 5000:
                    score += 8
                elif lead.nb_followers_instagram >= 1000:
                    score += 6
                elif lead.nb_followers_instagram >= 500:
                    score += 4
                elif lead.nb_followers_instagram >= 100:
                    score += 2
                else:
                    score += 1
            if lead.nb_posts_instagram and lead.nb_posts_instagram > 10:
                score += 3  # Activit√© r√©guli√®re
            if lead.bio_instagram:
                score += 2  # Bio pr√©sente
        
        # 5. Score Type d'Entreprise (10 points max)
        # Prioriser certains types d'entreprises pour la vid√©o
        if lead.business_type:
            high_value_types = [
                'restaurant', 'bar', 'cafe', 'hotel', 'spa', 'salon', 
                'gym', 'fitness', 'art_gallery', 'museum', 'theater',
                'event_venue', 'wedding_venue', 'tourist_attraction'
            ]
            if any(high_type in lead.business_type.lower() for high_type in high_value_types):
                score += 10
            elif 'retail' in lead.business_type.lower() or 'store' in lead.business_type.lower():
                score += 7
            else:
                score += 3
        
        # Limiter le score √† 100
        return min(score, 100.0)
    
    def get_leads(self, limit: int = 50) -> List[Lead]:
        """R√©cup√©rer les leads"""
        return Lead.query.order_by(Lead.created_at.desc()).limit(limit).all()
    
    def get_lead_by_id(self, lead_id: int) -> Optional[Lead]:
        """R√©cup√©rer un lead par ID"""
        return Lead.query.get(lead_id)
    
    def get_business_types(self) -> List[str]:
        """R√©cup√©rer les types d'entreprises disponibles"""
        return self.google_maps_service.get_business_types()
    
    def _is_valid_facebook_page(self, url: str) -> bool:
        """V√©rifie si l'URL Facebook est une page publique (pas un partage, post, event, etc.)"""
        if not url or 'facebook.com/' not in url:
            return False
        # Exclure les liens de partage, posts, events, groups, etc.
        exclure = ['/sharer', '/share', '/post', '/posts', '/events', '/groups', '/watch', '/permalink', '/media', '/photos', '/login', '/pages', '/search', '/reel', '/reels', '/story', '/stories']
        for exclu in exclure:
            if exclu in url:
                return False
        # Doit ressembler √† https://www.facebook.com/nomdelapage
        path = url.split('facebook.com/')[-1].split('?')[0].split('/')[0]
        return bool(path) and len(path) > 2
    
    def recalculate_all_opportunity_scores(self) -> Dict[str, Any]:
        """
        Recalculer les scores d'opportunit√© pour tous les leads existants
        
        Returns:
            R√©sultat du recalcul avec statistiques
        """
        SystemLogger.info("üîÑ [SCORING] D√©but du recalcul des scores d'opportunit√©...")
        
        try:
            # R√©cup√©rer tous les leads
            leads = Lead.query.all()
            SystemLogger.info(f"üìä [SCORING] {len(leads)} leads √† traiter")
            
            scores_updated = 0
            scores_unchanged = 0
            errors = 0
            
            for i, lead in enumerate(leads):
                try:
                    SystemLogger.info(f"üîß [SCORING] Traitement lead {i+1}/{len(leads)}: {lead.nom}")
                    
                    # Calculer le nouveau score
                    new_score = self._calculate_opportunity_score(lead)
                    old_score = lead.score_opportunite
                    
                    # Mettre √† jour le score
                    lead.score_opportunite = new_score
                    
                    if old_score != new_score:
                        scores_updated += 1
                        SystemLogger.info(f"üîÑ [SCORING] Score mis √† jour: {old_score} ‚Üí {new_score}")
                    else:
                        scores_unchanged += 1
                        SystemLogger.info(f"‚úÖ [SCORING] Score inchang√©: {new_score}")
                    
                    # Commit tous les 10 leads pour √©viter les timeouts
                    if (i + 1) % 10 == 0:
                        db.session.commit()
                        SystemLogger.info(f"üíæ [SCORING] Commit interm√©diaire ({i+1}/{len(leads)})")
                        
                except Exception as e:
                    errors += 1
                    SystemLogger.error(f"‚ùå [SCORING] Erreur pour {lead.nom}: {str(e)}")
                    continue
            
            # Commit final
            db.session.commit()
            
            result = {
                'success': True,
                'message': 'Recalcul des scores termin√©',
                'total_leads': len(leads),
                'scores_updated': scores_updated,
                'scores_unchanged': scores_unchanged,
                'errors': errors
            }
            
            SystemLogger.info(f"üéâ [SCORING] Recalcul termin√©:")
            SystemLogger.info(f"   - Total leads: {len(leads)}")
            SystemLogger.info(f"   - Scores mis √† jour: {scores_updated}")
            SystemLogger.info(f"   - Scores inchang√©s: {scores_unchanged}")
            SystemLogger.info(f"   - Erreurs: {errors}")
            
            return result
            
        except Exception as e:
            SystemLogger.error(f"‚ùå [SCORING] Erreur globale recalcul: {str(e)}")
            db.session.rollback()
            return {
                'success': False,
                'message': f'Erreur: {str(e)}',
                'total_leads': 0,
                'scores_updated': 0,
                'scores_unchanged': 0,
                'errors': 1
            } 