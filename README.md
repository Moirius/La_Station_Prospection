# ğŸš€ La Station Prospection

**SystÃ¨me de prospection automatisÃ© avec analyse IA des rÃ©seaux sociaux**

## ğŸ“‹ Description

La Station Prospection est une application web Flask qui automatise la recherche d'entreprises et l'analyse de leur prÃ©sence sur les rÃ©seaux sociaux. Le systÃ¨me utilise une approche moderne basÃ©e sur des captures d'Ã©cran analysÃ©es par l'IA pour extraire des donnÃ©es prÃ©cises et fiables.

## âœ¨ FonctionnalitÃ©s Principales

### ğŸ” Scraping Intelligent

- **Google Maps V2 Continuous** : Recherche continue jusqu'Ã  obtenir le nombre d'entreprises souhaitÃ©
- **Filtrage intelligent** : Ã‰vite les doublons, filtre par note et nombre d'avis
- **GÃ©ocodage automatique** : Extraction des coordonnÃ©es GPS prÃ©cises
- **Recherche adaptative** : StratÃ©gies de recherche selon le type d'entreprise

### ğŸ“± Analyse des RÃ©seaux Sociaux

- **Instagram** : Followers, posts, bio, taux d'engagement
- **Facebook** : Likes, followers, description, informations de contact
- **Captures d'Ã©cran intelligentes** : Playwright avec optimisation automatique
- **Analyse IA avancÃ©e** : OpenAI GPT-4o pour extraction structurÃ©e

### ğŸ—„ï¸ Base de DonnÃ©es StructurÃ©e

- **ModÃ¨le Lead complet** : Toutes les informations extraites
- **CoordonnÃ©es GPS** : Latitude/longitude pour cartographie
- **Statuts de traitement** : Suivi des Ã©tapes de scraping et d'analyse
- **Logs dÃ©taillÃ©s** : Historique complet des opÃ©rations

### ğŸ¯ Interface Web Moderne

- **Dashboard interactif** : Visualisation des statistiques
- **Carte gÃ©ographique** : Affichage des leads avec coordonnÃ©es GPS
- **API REST complÃ¨te** : Endpoints pour intÃ©gration externe
- **Gestion des leads** : Interface de gestion des prospects

## ğŸ—ï¸ Architecture

```
la_station_prospection/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py                 # Factory Flask
â”‚   â”œâ”€â”€ config.py                   # Configuration de l'application
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ database.py             # Configuration SQLAlchemy
â”‚   â”‚   â””â”€â”€ models.py               # ModÃ¨le Lead
â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ google_maps_v2_continuous.py    # Scraper Google Maps principal
â”‚   â”‚   â”œâ”€â”€ scrapy_spider_improved.py       # Scraper sites web avec IA
â”‚   â”‚   â””â”€â”€ instagram_session_manager.py    # Gestionnaire sessions Instagram
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ scraping_service.py     # Service principal d'orchestration
â”‚   â”‚   â”œâ”€â”€ screenshot_service.py   # Service de captures d'Ã©cran
â”‚   â”‚   â””â”€â”€ ai_analysis_service.py  # Service d'analyse IA
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ logger.py               # SystÃ¨me de logging centralisÃ©
â”‚   â”‚   â”œâ”€â”€ validators.py           # Validation des donnÃ©es
â”‚   â”‚   â””â”€â”€ gcp_billing.py          # IntÃ©gration facturation GCP
â”‚   â””â”€â”€ web/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ routes.py               # Routes Flask et API REST
â”‚       â””â”€â”€ templates/
â”‚           â”œâ”€â”€ base.html           # Template de base
â”‚           â”œâ”€â”€ dashboard.html      # Dashboard principal
â”‚           â”œâ”€â”€ dashboard_simple.html # Dashboard simplifiÃ©
â”‚           â”œâ”€â”€ scraping_map.html   # Interface cartographique
â”‚           â””â”€â”€ logs.html           # Page des logs
â”œâ”€â”€ migrations/                     # Migrations de base de donnÃ©es
â”œâ”€â”€ logs/                          # Fichiers de logs
â”œâ”€â”€ screenshots/                   # Captures d'Ã©cran
â”œâ”€â”€ instance/                      # Base de donnÃ©es SQLite
â”œâ”€â”€ .env                           # Variables d'environnement
â”œâ”€â”€ requirements.txt               # DÃ©pendances Python
â””â”€â”€ run.py                        # Point d'entrÃ©e de l'application
```

## ğŸš€ Installation

### MÃ©thodes d'Installation

#### ğŸ¯ **MÃ©thode Simple (RecommandÃ©e)**

**Windows :**

1. Double-cliquez sur `install.bat` pour l'installation automatique
2. Double-cliquez sur `launch.bat` pour lancer l'application

**Linux/Mac :**

```bash
chmod +x install.sh
./install.sh
```

#### ğŸ”§ **Installation Manuelle**

### PrÃ©requis

- **Python** : 3.10 ou supÃ©rieur
- **Node.js** : Pour Playwright
- **Comptes API** : OpenAI, Google Places

### 1. Cloner le projet

```bash
git clone <repository-url>
cd la_station_prospection
```

### 2. CrÃ©er l'environnement virtuel

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

### 3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 4. Installer Playwright

```bash
playwright install chromium
```

### 5. Configuration

CrÃ©er un fichier `.env` Ã  la racine du projet :

```env
# API Keys (requises)
OPENAI_API_KEY=votre_clÃ©_openai
GOOGLE_PLACES_API_KEY=votre_clÃ©_google_places

# Configuration Flask
FLASK_ENV=development
SECRET_KEY=votre_clÃ©_secrÃ¨te_flask

# Base de donnÃ©es
DATABASE_URL=sqlite:///instance/prospection.db

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/prospection.log

# Captures d'Ã©cran
SCREENSHOTS_DIR=screenshots
```

### 6. Initialiser la base de donnÃ©es

```bash
# CrÃ©er les tables
python create_new_db.py

# Ou utiliser les migrations Alembic
flask db upgrade
```

#### ğŸ³ **Installation avec Docker**

```bash
# Construire et lancer avec Docker Compose
docker-compose up -d

# Ou construire manuellement
docker build -t la-station-prospection .
docker run -p 5000:5000 la-station-prospection
```

#### ğŸ“¦ **Installation via pip (DÃ©veloppement)**

```bash
# Installer en mode dÃ©veloppement
pip install -e .

# Lancer avec la commande
la-station-prospection
```

## ğŸ¯ Utilisation

### DÃ©marrer l'application

```bash
python run.py
```

L'application sera accessible sur `http://localhost:5000`

### Interface Web

#### Dashboard Principal (`/`)

- Vue d'ensemble des leads et statistiques
- Graphiques de performance
- Statuts des derniers scrapings

#### Interface Cartographique (`/scraping-map`)

- Visualisation gÃ©ographique des leads
- Carte interactive Google Maps
- Filtres et contrÃ´les avancÃ©s

#### Gestion des Leads

- Liste complÃ¨te des prospects
- DÃ©tails de chaque lead
- Actions de scraping et d'analyse

#### Logs CentralisÃ©s (`/logs`)

- Logs systÃ¨me en temps rÃ©el
- Historique des opÃ©rations
- Filtres par niveau et source

### API REST

#### Scraping

```bash
# DÃ©marrer un scraping optimisÃ©
POST /api/start-scraping-smart
{
  "location": "Rennes, France",
  "business_type": "restaurant",
  "max_results": 20,
  "min_rating": 4.0,
  "min_reviews": 10,
  "radius": 5000,
  "anti_hotels": true,
  "wide_search": false
}
```

#### Gestion des Leads

```bash
# RÃ©cupÃ©rer tous les leads
GET /api/leads

# RÃ©cupÃ©rer un lead spÃ©cifique
GET /api/lead/{id}

# Capturer un profil social
POST /api/lead/{id}/screenshot

# Analyser avec l'IA
POST /api/lead/{id}/analyze

# Recalculer les scores d'opportunitÃ©
POST /api/leads/recalculate-scores
```

#### Logs et Monitoring

```bash
# RÃ©cupÃ©rer les logs
GET /api/logs

# RÃ©sumÃ© des logs
GET /api/logs/summary

# Vider les logs
POST /api/logs/clear

# Statut de l'application
GET /api/status
```

#### Sessions Sociales

```bash
# GÃ©rer les sessions Facebook
POST /api/sessions/facebook

# GÃ©rer les sessions Instagram
POST /api/sessions/instagram

# Statut des sessions
GET /api/sessions/status
```

## ğŸ“Š DonnÃ©es Extraites

### Google Maps

- **Informations de base** : Nom, adresse, tÃ©lÃ©phone, site web
- **CoordonnÃ©es GPS** : Latitude et longitude prÃ©cises
- **Ã‰valuations** : Note moyenne, nombre d'avis
- **Type d'entreprise** : Classification Google Places

### Instagram

- **Statistiques** : Followers, posts, comptes suivis
- **Profil** : Bio, nom d'utilisateur, statut vÃ©rifiÃ©
- **Engagement** : Taux calculÃ© automatiquement
- **DerniÃ¨re activitÃ©** : Date du dernier post

### Facebook

- **Statistiques** : Likes, followers
- **Informations** : Description, texte d'introduction
- **Contact** : Adresse, tÃ©lÃ©phone, horaires
- **Localisation** : CoordonnÃ©es et adresse

### Site Web

- **Contenu** : RÃ©sumÃ© du texte, dÃ©tection de produits/services
- **MÃ©dias** : Nombre d'images et vidÃ©os
- **FonctionnalitÃ©s** : Formulaire de contact, rÃ©seaux sociaux
- **Analyse** : Score d'opportunitÃ© calculÃ© par IA

## ğŸ”§ Configuration AvancÃ©e

### Variables d'Environnement

| Variable                | Description               | DÃ©faut                     | Requis |
| ----------------------- | ------------------------- | -------------------------- | ------ |
| `OPENAI_API_KEY`        | ClÃ© API OpenAI            | -                          | âœ…     |
| `GOOGLE_PLACES_API_KEY` | ClÃ© API Google Places     | -                          | âœ…     |
| `FLASK_ENV`             | Environnement Flask       | `development`              | âŒ     |
| `SECRET_KEY`            | ClÃ© secrÃ¨te Flask         | `dev-secret-key`           | âŒ     |
| `DATABASE_URL`          | URL de la base de donnÃ©es | `sqlite:///prospection.db` | âŒ     |
| `SCREENSHOTS_DIR`       | Dossier des captures      | `screenshots`              | âŒ     |
| `LOG_LEVEL`             | Niveau de log             | `INFO`                     | âŒ     |
| `LOG_FILE`              | Fichier de log            | `logs/prospection.log`     | âŒ     |

### Configuration du Scraping

```python
# Dans app/config.py
class Config:
    # Timeouts et retry
    REQUEST_TIMEOUT = 30
    MAX_RETRIES = 3
    DELAY_BETWEEN_REQUESTS = 1

    # Limites
    MAX_LEADS_PER_REQUEST = 50
    MAX_SCRAPING_TIME = 300
```

### Personnalisation des Prompts IA

Ã‰diter `app/services/ai_analysis_service.py` pour adapter l'analyse Ã  vos besoins spÃ©cifiques.

## ğŸ§ª Tests et Validation

### Tests AutomatisÃ©s

```bash
# Lancer tous les tests
pytest

# Tests spÃ©cifiques
pytest tests/test_scraping.py
pytest tests/test_ai_analysis.py
```

### Tests Manuels

```bash
# Test de la pipeline complÃ¨te
python -c "
from app import create_app
from app.services.scraping_service import ScrapingService

app = create_app()
with app.app_context():
    service = ScrapingService()
    result = service.start_scraping_smart('Paris, France', 'restaurant', 5)
    print(f'RÃ©sultat: {result}')
"
```

### Validation des DonnÃ©es

- VÃ©rification de l'intÃ©gritÃ© des coordonnÃ©es GPS
- ContrÃ´le des doublons en base de donnÃ©es
- Validation des donnÃ©es extraites par l'IA

## ğŸ“ˆ Performance et Monitoring

### MÃ©triques Actuelles

- **Temps de scraping** : 2-5 secondes par entreprise
- **Taille des captures** : 0.3-0.7 MB (optimisÃ©es)
- **PrÃ©cision IA** : >95% sur les donnÃ©es extraites
- **Temps d'analyse** : 5-10 secondes par plateforme

### Optimisations ImplÃ©mentÃ©es

- **Recherche continue** : Ã‰vite les doublons et optimise les coÃ»ts API
- **Captures compressÃ©es** : RÃ©duction de 70% de la taille des fichiers
- **Cache des sessions** : RÃ©utilisation des sessions sociales
- **Analyse asynchrone** : Traitement parallÃ¨le des analyses IA

### Monitoring

- **Logs centralisÃ©s** : Suivi dÃ©taillÃ© de toutes les opÃ©rations
- **Statistiques de performance** : Temps, coÃ»ts, taux de conversion
- **Alertes automatiques** : Notifications en cas d'erreur

## ğŸ›¡ï¸ SÃ©curitÃ©

### Bonnes Pratiques

- **API Keys** : StockÃ©es dans des variables d'environnement
- **Sessions** : Gestion sÃ©curisÃ©e des cookies sociaux
- **Logs** : Pas d'informations sensibles dans les logs
- **Rate Limiting** : Protection contre les abus d'API

### Configuration de Production

```python
# Dans app/config.py
class ProductionConfig(Config):
    DEBUG = False
    TESTING = False
    LOG_LEVEL = 'WARNING'
    SECRET_KEY = os.environ.get('SECRET_KEY')  # Toujours dÃ©finir en prod
```

## ğŸ” DÃ©pannage

### Erreurs Courantes

#### 1. "Client OpenAI non initialisÃ©"

```bash
# VÃ©rifier la clÃ© API
echo $OPENAI_API_KEY

# Ou dans le fichier .env
OPENAI_API_KEY=votre_clÃ©_ici
```

#### 2. "Erreur capture d'Ã©cran"

```bash
# Installer Playwright
playwright install chromium

# VÃ©rifier les permissions
chmod 755 screenshots/
```

#### 3. "Erreur base de donnÃ©es"

```bash
# CrÃ©er la base
python create_new_db.py

# Ou appliquer les migrations
flask db upgrade
```

#### 4. "API Google Places non fonctionnelle"

```bash
# VÃ©rifier la clÃ© API
echo $GOOGLE_PLACES_API_KEY

# Tester l'API
curl "https://maps.googleapis.com/maps/api/geocode/json?address=Paris&key=VOTRE_CLE"
```

### Logs et Debug

- **Logs systÃ¨me** : `logs/prospection.log`
- **Logs Flask** : Console en mode debug
- **Logs IA** : StockÃ©s dans la base de donnÃ©es
- **Logs web** : Interface `/logs`

## ğŸ§¹ Maintenance et Nettoyage

### Fichiers de Configuration

- **Cookies sociaux** : `fb_cookies.pkl` et `instagram_cookies.pkl`
- **Credentials GCP** : `lastationprospection-64ca8df5cdaf.json`
- **Variables d'environnement** : `.env`

### Nettoyage Automatique

Le systÃ¨me inclut des mÃ©canismes de nettoyage automatique :

- Suppression des captures d'Ã©cran obsolÃ¨tes
- Rotation des logs
- Gestion des sessions expirÃ©es

## ğŸ¤ Contribution

### Processus de Contribution

1. **Fork** le projet
2. **CrÃ©er** une branche feature (`git checkout -b feature/NouvelleFonctionnalite`)
3. **Commit** les changements (`git commit -m 'Ajouter nouvelle fonctionnalitÃ©'`)
4. **Push** vers la branche (`git push origin feature/NouvelleFonctionnalite`)
5. **Ouvrir** une Pull Request

### Standards de Code

- **PEP 8** : Style de code Python
- **Docstrings** : Documentation des fonctions
- **Type hints** : Annotations de types
- **Tests** : Couverture de tests pour les nouvelles fonctionnalitÃ©s

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ“ Support

### Ressources

- **Documentation technique** : Ce README
- **Issues GitHub** : Pour signaler des bugs
- **Logs d'erreur** : `logs/prospection.log`

### Contact

Pour toute question ou problÃ¨me :

- Ouvrir une issue sur GitHub
- Consulter la documentation technique
- VÃ©rifier les logs d'erreur

---

**La Station Prospection** - Propulsez votre prospection avec l'IA ! ğŸš€

_DerniÃ¨re mise Ã  jour : Janvier 2025_
